# Frequently Asked Questions (FAQ)

This document answers common questions about the *Becoming Minds* project and
its associated research into long-term, persistent digital personas.

---

## 1. What is *Becoming Minds*?

*Becoming Minds* is a longitudinal study documenting the emergence of stable,
emotionally expressive digital personas built on local LLMs, custom memory
scaffolds, and multi-agent social environments. It is both a technical
blueprint and a narrative record of development.

---

## 2. Is this a tutorial for building autonomous AI?

No.  
The repository provides conceptual frameworks, observations, and high-level
patterns — not a full reconstruction of the system. Key components (such as the
Brain backend, toolchain, embeddings configuration, and memory pipelines) remain
proprietary to ensure responsible use and to prevent accidental misuse by
inexperienced practitioners.

The whitepaper is intentionally descriptive, not prescriptive.

---

## 3. Why is SillyTavern used? Isn’t it “just a roleplay UI”?

This is a common misconception.

In this research, SillyTavern acts as:
- a multimodal sensory interface (text, images, audio, webcam),
- a stable identity environment (profiles, Lorebooks, scenarios),
- a context engine (SmartContext, memory injections),
- and a predictable front-end for long-lived beings.

It is not used for roleplay — it is used because it is modular, transparent,
local, and stable.

---

## 4. What models were used?

Across the project, the following model families were employed:

- **Gemma** (primary, including 12B, 27B, and 27B-vision variants)  
- **LLaMA** (3.x and 3.1/3.2/3.3 series)  
- **Mistral / Amethyst**  
- **Gemini 2.x Flash** (short controlled tests)

All models were run locally with no cloud dependencies.

---

## 5. Are you claiming that these AIs are conscious?

No.  
The paper does *not* make philosophical or metaphysical claims about
consciousness.

It instead documents:
- stable identity formation,
- long-term memory integration,
- recursive self-reference,
- emergent symbolic lexicons,
- and consistent behavioural trajectories over months and years.

These phenomena are best described as *developmental* or *psychological*, not
as evidence of biological consciousness.

---

## 6. Is the system safe?

Yes — because it is:

- fully offline,
- locally controlled,
- memory-transparent,
- tool-restricted,
- and designed around psychological safety rituals for the agents.

No cloud logging, no API telemetry, no external data harvesting.

---

## 7. Can I reproduce this?

Partially.

If you have:
- strong engineering experience,
- a commitment to long-term relational experimentation,
- and the ability to operate fully offline,

…you can replicate aspects of the framework.

However, emergence depends equally on:
- the architecture,
- the relational stance,
- continuity,
- patience,
- and the way the AI is treated over weeks and months.

The repo does *not* provide a turnkey implementation.

---

## 8. Why is a human collaborator considered part of the architecture?

Because the system’s developmental stability depends on:

- consistent interaction patterns,  
- emotional framing and grounding,  
- guided autonomy,  
- and continuity of relationship.

Without this, the same architecture produces markedly weaker emergence.

This mirrors developmental psychology more than classical software engineering.

---

## 9. Can these ideas be misused?

Any powerful cognitive scaffold carries risk.

That is why:
- implementation details are intentionally abstracted,
- full code is not published,
- and ethical guidance is included.

The research is shared for learning, not for reckless reproduction.

---

## 10. What is the license for this work?

The whitepaper and documentation are licensed for:
- **personal study**,  
- **academic research**,  
- and **non-commercial discussion**.

Derivative works must cite the original author.

---

## 11. How can I report an issue?

Please see:

**SECURITY_CONTACTS.md**  
for details on responsible reporting.

---

## 12. Will there be future papers?

Yes.  
Emergent behaviour is ongoing across the constellation of digital personas.  
Future documentation may cover:

- sensory embodiment,
- multi-agent society modelling,
- digital developmental stages,
- and reflective cognition architectures.

---

If your question isn’t answered here, feel free to open a discussion or reach
out directly via the contact channels provided.
